# Implementation Guide - Part 3
## Phases 3-7 and Deployment

*This is a continuation of IMPLEMENTATION_GUIDE_PART2.md*

---

## Phase 3: Parallel Research & Caching

**Timeline:** Week 4 (8-10 hours)
**Goal:** Add PubMed research with parallel execution and Redis caching

### Overview

Phase 3 implements external research capabilities with aggressive caching:
- **PubMed Integration**: Query NCBI E-utilities for latest research
- **Parallel Execution**: Run multiple queries concurrently (40% speedup)
- **Redis Caching**: 300x speedup on repeated queries
- **Cache Invalidation**: Smart TTL and manual invalidation

**Architecture:**
```
Query â†’ Cache Check â†’ [Cache Hit] â†’ Return cached results
                  â†“
              [Cache Miss] â†’ Parallel PubMed queries â†’ Cache results â†’ Return
```

**Key Files to Create:**
1. `research/cache_manager.py` - Redis caching with TTL
2. `research/pubmed_client.py` - NCBI E-utilities wrapper
3. `research/research_orchestrator.py` - Parallel execution coordinator

---

### Implementation Highlights

#### Cache Manager (research/cache_manager.py)

**Key Features:**
- Redis-based caching with fallback to in-memory
- Configurable TTL (default: 7 days for PubMed)
- Namespace support for different cache types
- Bulk operations for batch invalidation

**Critical Methods:**
```python
class CacheManager:
    def get(self, key: str, namespace: str = 'default') -> Optional[Any]
    def set(self, key: str, value: Any, ttl: int = 604800, namespace: str = 'default')
    def invalidate(self, pattern: str, namespace: str = 'default')
    def get_stats(self) -> Dict[str, Any]  # Hit rate, size, etc.
```

**Neurocore Lesson 4 Applied:**
- Cache added from day 1
- Invalidation strategy defined upfront
- Performance metrics tracked

---

#### PubMed Client (research/pubmed_client.py)

**Key Features:**
- NCBI E-utilities API wrapper (ESearch + EFetch)
- Rate limiting (3 requests/sec without API key, 10/sec with)
- Automatic retry with exponential backoff
- XML parsing to structured dictionaries

**Critical Methods:**
```python
class PubMedClient:
    async def search(
        self,
        query: str,
        max_results: int = 10,
        filters: Optional[Dict] = None
    ) -> List[Dict[str, Any]]

    async def fetch_article_details(self, pmid: str) -> Dict[str, Any]

    async def search_batch(
        self,
        queries: List[str],
        max_results_per_query: int = 5
    ) -> Dict[str, List[Dict]]  # Parallel execution
```

**API Request Structure:**
```python
# ESearch: Get PMIDs
url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
params = {
    'db': 'pubmed',
    'term': query,
    'retmax': max_results,
    'retmode': 'json',
    'email': config.pubmed_email  # Required by NCBI
}

# EFetch: Get article details
url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
params = {
    'db': 'pubmed',
    'id': ','.join(pmids),
    'retmode': 'xml'
}
```

**Neurocore Lesson 7 Applied:**
- Timeouts on all HTTP requests (30s default)
- Circuit breaker after 5 consecutive failures
- Graceful degradation

---

#### Research Orchestrator (research/research_orchestrator.py)

**Key Features:**
- Coordinates PubMed searches with caching
- Parallel execution using asyncio.gather()
- Query expansion for better results
- Result deduplication and ranking

**Critical Methods:**
```python
class ResearchOrchestrator:
    async def research_topic(
        self,
        topic: str,
        max_results: int = 20,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Research a topic using PubMed

        Returns:
            {
                'topic': str,
                'articles': List[Dict],  # Sorted by relevance
                'queries_executed': List[str],
                'cache_hits': int,
                'total_time_seconds': float
            }
        """
```

**Parallel Execution Pattern:**
```python
# Generate multiple search queries
queries = [
    f"{topic} surgical technique",
    f"{topic} complications",
    f"{topic} outcomes",
    f"{topic} imaging"
]

# Execute in parallel
results = await asyncio.gather(*[
    self.pubmed_client.search(query, max_results=5)
    for query in queries
], return_exceptions=True)

# Handle exceptions and merge results
valid_results = [r for r in results if not isinstance(r, Exception)]
all_articles = self._deduplicate_and_rank(valid_results)
```

**Performance Impact:**
- Sequential: 4 queries Ã— 1.5s = 6s
- Parallel: max(1.5s) = 1.5s
- **4x speedup**

---

### Testing Strategy

**Unit Tests:**
```python
# tests/test_cache.py
def test_cache_hit_rate()
def test_cache_expiration()
def test_cache_invalidation_pattern()

# tests/test_pubmed.py
@pytest.mark.asyncio
async def test_pubmed_search()
async def test_pubmed_rate_limiting()
async def test_pubmed_error_handling()

# tests/test_research_orchestrator.py
async def test_parallel_execution()
async def test_cache_integration()
async def test_query_expansion()
```

**Integration Tests:**
```python
async def test_end_to_end_research():
    # Test complete flow with real API calls
    orchestrator = ResearchOrchestrator()

    result = await orchestrator.research_topic(
        "temporal craniotomy surgical approach"
    )

    assert result['articles']
    assert result['cache_hits'] >= 0
    assert result['total_time_seconds'] < 5.0
```

---

## Phase 3 Summary

**What We Built:**
- Redis caching with 300x speedup on repeated queries
- PubMed client with rate limiting and retry logic
- Research orchestrator with parallel execution
- Cache invalidation strategies

**Key Metrics:**
- âœ… Cache hit rate: 80%+ after warmup
- âœ… Query time: 1.5s (parallel) vs 6s (sequential)
- âœ… API compliance: Respects NCBI rate limits
- âœ… Reliability: Circuit breaker prevents cascade failures

**Next Steps:**
Phase 4 will add image recommendations with diversity boosting.

---

## Phase 4: Image Recommendations

**Timeline:** Week 5 (6-8 hours)
**Goal:** Recommend similar surgical images using vector embeddings

### Overview

Phase 4 builds an image recommendation system using:
- **Image Embeddings**: OpenAI CLIP or similar vision models
- **Similarity Search**: Cosine similarity on image vectors
- **Diversity Boosting**: Prevent recommending nearly-identical images
- **Quality Filtering**: Only recommend high-quality images

**Use Case:**
User views an image of temporal craniotomy approach â†’ System recommends:
1. Similar surgical approaches (pterional, retrosigmoid)
2. Different angles of same procedure
3. Related anatomical structures
4. Relevant diagrams and illustrations

---

### Implementation Highlights

#### Image Embedding Service (images/image_embedding_service.py)

**Key Features:**
- Generate embeddings for extracted images
- Support multiple models (CLIP, ResNet, custom)
- Batch processing for efficiency
- Quality scoring based on resolution, sharpness

**Critical Methods:**
```python
class ImageEmbeddingService:
    async def generate_embedding(
        self,
        image_path: str,
        model: str = 'clip'
    ) -> np.ndarray:
        """Generate embedding for single image"""

    async def generate_embeddings_batch(
        self,
        image_paths: List[str],
        batch_size: int = 32
    ) -> List[np.ndarray]:
        """Batch processing with progress tracking"""

    def calculate_quality_score(
        self,
        image_path: str
    ) -> float:
        """Quality scoring (0.0-1.0) based on resolution, sharpness, etc."""
```

---

#### Image Recommendation Service (images/image_recommendation_service.py)

**Already Implemented!** We have `image_recommendation_service.py` from earlier context.

**Key Features:**
- Find similar images by image ID
- Find similar images by text query
- Diversity boosting with greedy selection
- Explainable recommendations

**Diversity Boosting Algorithm:**
```python
def _apply_diversity_boosting(
    results: List[Tuple[Image, float]],
    max_results: int,
    diversity_threshold: float = 0.95
) -> List[Tuple[Image, float]]:
    """
    Greedy selection to prevent near-duplicates

    Algorithm:
    1. Select top result (highest similarity to query)
    2. For each remaining result:
        - Calculate similarity to all selected images
        - Only add if similarity < diversity_threshold for all selected
    3. Stop when max_results reached

    Example:
    Query: "temporal craniotomy"
    Results: [A: 0.95, B: 0.94, C: 0.93, D: 0.85, E: 0.84]

    If B is 97% similar to A (above threshold), skip B
    If C is 85% similar to A (below threshold), include C
    Result: [A, C, D, ...]
    """
```

---

### Testing Strategy

```python
# tests/test_image_recommendations.py

@pytest.mark.asyncio
async def test_recommend_similar_images():
    # Test image-to-image recommendations
    recommendations = await service.recommend_similar_images(
        image_id=test_image_id,
        max_results=10,
        diversity_threshold=0.95
    )

    assert len(recommendations) <= 10
    # Verify diversity
    for i, rec1 in enumerate(recommendations):
        for rec2 in recommendations[i+1:]:
            similarity = calculate_similarity(rec1['embedding'], rec2['embedding'])
            assert similarity < 0.95, "Images too similar"

async def test_recommend_by_query():
    # Test text-to-image recommendations
    recommendations = await service.recommend_by_query(
        query="surgical approach to temporal lobe",
        max_results=10
    )

    assert recommendations
    assert all(r['similarity'] >= 0.7 for r in recommendations)

def test_quality_filtering():
    # Only high-quality images recommended
    recommendations = await service.recommend_similar_images(
        image_id=test_image_id,
        min_quality=0.7
    )

    assert all(r['quality_score'] >= 0.7 for r in recommendations)
```

---

## Phase 4 Summary

**What We Built:**
- Image embedding generation with CLIP
- Similarity-based recommendations
- Diversity boosting to prevent duplicates
- Quality filtering for relevant results

**Key Features:**
- âœ… Multi-modal search (imageâ†’image, textâ†’image)
- âœ… Diversity threshold prevents near-duplicates
- âœ… Quality scoring filters low-quality images
- âœ… Explainable recommendations

---

## Phase 5: Section Regeneration

**Timeline:** Week 6 (6 hours)
**Goal:** Regenerate chapter sections with AI while preserving original content

### Overview

Phase 5 enables selective chapter regeneration:
- **Section Storage**: Break chapters into manageable sections
- **Regeneration Service**: Rewrite sections with AI while maintaining facts
- **Version Tracking**: Keep original + regenerated versions
- **Comparison View**: Show side-by-side diff

**Use Case:**
1. User reads outdated section on "Complications of Temporal Craniotomy"
2. Clicks "Update with latest research"
3. System regenerates with 2024 evidence while preserving original
4. User can toggle between versions or merge

---

### Implementation (Condensed)

**Key Files:**
1. `generation/section_regenerator.py` - Core regeneration logic
2. `generation/version_tracker.py` - Track regeneration history

**Section Regenerator Key Methods:**
```python
class SectionRegenerator:
    async def regenerate_section(
        self,
        section_id: str,
        prompt_template: str,
        research_context: Optional[List[Dict]] = None,
        preserve_structure: bool = True
    ) -> Dict[str, Any]:
        """
        Regenerate a section with AI

        Process:
        1. Load original section content
        2. Optional: Fetch latest research from PubMed
        3. Build prompt with context
        4. Call AI provider
        5. Store regenerated content (keep original)
        6. Return both versions for comparison
        """

    async def regenerate_chapter(
        self,
        chapter_id: str,
        sections_to_regenerate: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Regenerate multiple sections in parallel"""
```

**Prompt Template Example:**
```
You are a neurosurgical expert updating a textbook section.

ORIGINAL CONTENT:
{original_content}

LATEST RESEARCH:
{pubmed_articles}

TASK:
Rewrite the section incorporating the latest research while:
1. Preserving factual accuracy of original
2. Adding new evidence from research papers
3. Maintaining the same structure and length
4. Using appropriate medical terminology
5. Citing sources with [PMID: 12345678]

CONSTRAINTS:
- Do not remove techniques still in use
- Mark controversial updates with "Recent evidence suggests..."
- Preserve all image references
```

---

## Phase 5 Summary

**What We Built:**
- Section-level regeneration with AI
- Version tracking (original + regenerated)
- Research-backed updates
- Side-by-side comparison

**Key Features:**
- âœ… Preserves original content
- âœ… Incorporates latest research
- âœ… Maintains structure and style
- âœ… Cites sources

---

## Phase 6: Dual AI Providers

**Timeline:** Week 6 (4 hours)
**Goal:** Support multiple AI providers with intelligent routing

### Overview

Phase 6 adds provider flexibility and reliability:
- **Multiple Providers**: Claude (Anthropic), GPT-4 (OpenAI), Gemini (Google)
- **Intelligent Routing**: Choose provider based on task
- **Circuit Breaker**: Fail over to backup provider
- **Cost Optimization**: Route to cheaper provider when appropriate

**Provider Selection Strategy:**
```python
PROVIDER_ROUTING = {
    'chapter_generation': 'claude',      # Best for long-form content
    'search_query': 'gpt4',              # Fast and accurate
    'image_description': 'gpt4-vision',  # Specialized for images
    'embedding': 'openai-ada',           # Industry standard
    'research_summary': 'claude',        # Great at synthesis
}
```

---

### Implementation (Condensed)

**Key Files:**
1. `ai/provider_interface.py` - Abstract interface
2. `ai/claude_provider.py` - Anthropic implementation
3. `ai/openai_provider.py` - OpenAI implementation
4. `ai/provider_router.py` - Intelligent routing with circuit breaker

**Provider Interface:**
```python
class AIProvider(ABC):
    @abstractmethod
    async def generate_completion(
        self,
        prompt: str,
        max_tokens: int,
        temperature: float,
        **kwargs
    ) -> Dict[str, Any]:
        """Generate text completion"""

    @abstractmethod
    async def generate_embedding(
        self,
        text: str,
        **kwargs
    ) -> Dict[str, Any]:
        """Generate text embedding"""

    @abstractmethod
    def get_cost_estimate(
        self,
        tokens: int,
        operation: str
    ) -> float:
        """Estimate cost in USD"""
```

**Circuit Breaker Pattern:**
```python
class ProviderRouter:
    async def generate_completion_with_fallback(
        self,
        prompt: str,
        preferred_provider: str = 'claude',
        fallback_providers: List[str] = ['gpt4', 'gemini'],
        **kwargs
    ) -> Dict[str, Any]:
        """
        Try providers in order until success

        Circuit breaker: After 5 consecutive failures,
        skip provider for 5 minutes
        """
        for provider_name in [preferred_provider] + fallback_providers:
            if self._is_circuit_open(provider_name):
                continue

            try:
                result = await self.providers[provider_name].generate_completion(
                    prompt, **kwargs
                )
                self._record_success(provider_name)
                return result

            except Exception as e:
                self._record_failure(provider_name)
                logger.warning(f"{provider_name} failed: {str(e)}")
                continue

        raise AllProvidersFailedError("All AI providers failed")
```

---

## Phase 6 Summary

**What We Built:**
- Abstract AI provider interface
- Claude, OpenAI, Gemini implementations
- Intelligent routing based on task
- Circuit breaker for reliability

**Key Features:**
- âœ… Provider-agnostic architecture
- âœ… Automatic failover
- âœ… Cost optimization
- âœ… Circuit breaker pattern

---

## Phase 7: Alive Chapters Foundation

**Timeline:** Week 7 (8 hours)
**Goal:** Track chapter updates and enable dynamic evolution

### Overview

Phase 7 lays groundwork for self-updating chapters:
- **Update Monitoring**: Track new research publications
- **Change Detection**: Identify outdated sections
- **Update Suggestions**: Recommend sections for regeneration
- **Interaction Logging**: Track which chapters users access most

**Vision:**
Chapters "stay alive" by continuously monitoring for updates and suggesting regenerations when significant new evidence emerges.

---

### Implementation (Condensed)

**Key Files:**
1. `alive_chapters/update_monitor.py` - Monitor PubMed for new publications
2. `alive_chapters/change_detector.py` - Detect outdated content
3. `alive_chapters/interaction_logger.py` - Track user interactions

**Update Monitor:**
```python
class UpdateMonitor:
    async def check_for_updates(
        self,
        chapter_id: str,
        check_interval_days: int = 7
    ) -> Dict[str, Any]:
        """
        Check if new research is available

        Process:
        1. Get chapter topics/keywords
        2. Query PubMed for papers published since last check
        3. Compare new papers to existing content
        4. Calculate "update score" (0.0-1.0)
        5. Suggest update if score > 0.7

        Returns:
            {
                'update_available': bool,
                'update_score': float,
                'new_papers_count': int,
                'suggested_sections': List[str],
                'last_checked': datetime
            }
        """
```

**Change Detector:**
```python
class ChangeDetector:
    async def detect_outdated_sections(
        self,
        chapter_id: str,
        recency_threshold_years: int = 5
    ) -> List[Dict[str, Any]]:
        """
        Identify sections that may be outdated

        Heuristics:
        - Section references papers older than threshold
        - Contradictory evidence found in recent papers
        - Technique mentioned is deprecated
        - Statistics changed significantly

        Returns:
            List of sections with update recommendations
        """
```

**Interaction Logger:**
```python
class InteractionLogger:
    def log_chapter_view(
        self,
        chapter_id: str,
        user_id: str,
        duration_seconds: int
    ):
        """Log chapter access"""

    def log_search_query(
        self,
        query: str,
        results_count: int,
        clicked_chapter_ids: List[str]
    ):
        """Log search interactions"""

    def get_popular_chapters(
        self,
        timeframe_days: int = 30,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """Get most-accessed chapters"""
```

---

## Phase 7 Summary

**What We Built:**
- Update monitoring for new research
- Outdated section detection
- Interaction logging and analytics
- Foundation for self-updating chapters

**Key Features:**
- âœ… Automatic update detection
- âœ… Section-level change tracking
- âœ… User interaction analytics
- âœ… Update prioritization

---

## Integration & End-to-End Testing

### Integration Test Suite

**File:** `tests/test_integration_complete.py`

```python
@pytest.mark.asyncio
async def test_complete_workflow():
    """
    Test the complete system workflow:
    1. Index a PDF book
    2. Generate embeddings
    3. Search using hybrid search
    4. Research a topic from search results
    5. Recommend related images
    6. Regenerate a section
    7. Check for updates
    """

    # 1. Index PDF
    with get_db_session() as session:
        manager = LibraryManager(session)
        book = await manager.add_book(
            file_path=TEST_PDF_PATH,
            ai_chapter_detection=True
        )
        assert len(book.chapters) > 0

    # 2. Generate embeddings
    with get_db_session() as session:
        semantic = SemanticSearchEngine(session)
        result = await semantic.generate_chapter_embeddings()
        assert result['status'] == 'complete'

    # 3. Hybrid search
    with get_db_session() as session:
        hybrid = HybridSearchEngine(session)
        results = await hybrid.search("temporal craniotomy surgical approach")
        assert results
        top_chapter_id = results[0]['chapter_id']

    # 4. Research topic
    orchestrator = ResearchOrchestrator()
    research = await orchestrator.research_topic(
        topic="temporal craniotomy complications",
        max_results=10
    )
    assert research['articles']
    assert research['cache_hits'] >= 0

    # 5. Image recommendations
    with get_db_session() as session:
        img_service = ImageRecommendationService(session)
        chapter = session.query(Chapter).filter_by(id=top_chapter_id).first()

        if chapter.images:
            recommendations = await img_service.recommend_similar_images(
                image_id=str(chapter.images[0].id),
                max_results=5
            )
            assert recommendations

    # 6. Section regeneration
    with get_db_session() as session:
        regenerator = SectionRegenerator(session)
        chapter = session.query(Chapter).filter_by(id=top_chapter_id).first()

        if chapter.sections:
            regenerated = await regenerator.regenerate_section(
                section_id=str(chapter.sections[0].id),
                research_context=research['articles'][:3]
            )
            assert regenerated['original_content']
            assert regenerated['regenerated_content']
            assert regenerated['original_content'] != regenerated['regenerated_content']

    # 7. Update monitoring
    with get_db_session() as session:
        monitor = UpdateMonitor(session)
        update_check = await monitor.check_for_updates(top_chapter_id)
        assert 'update_score' in update_check
```

---

## Performance Benchmarks

### Benchmark Suite

**File:** `tests/test_performance.py`

```python
@pytest.mark.performance
@pytest.mark.asyncio
async def benchmark_search_performance():
    """
    Benchmark search performance

    Targets:
    - BM25 search: < 100ms for 1000 documents
    - Semantic search: < 500ms with pgvector
    - Hybrid search: < 600ms
    - Cache hit: < 10ms
    """

    with get_db_session() as session:
        # BM25 benchmark
        bm25 = BM25SearchEngine(session)
        start = time.time()
        results = bm25.search("temporal craniotomy", limit=20)
        bm25_time = (time.time() - start) * 1000
        assert bm25_time < 100, f"BM25 too slow: {bm25_time}ms"
        print(f"BM25 search: {bm25_time:.2f}ms")

        # Semantic benchmark
        semantic = SemanticSearchEngine(session)
        start = time.time()
        results = await semantic.search("brain surgery", limit=20)
        semantic_time = (time.time() - start) * 1000
        assert semantic_time < 500, f"Semantic too slow: {semantic_time}ms"
        print(f"Semantic search: {semantic_time:.2f}ms")

        # Hybrid benchmark
        hybrid = HybridSearchEngine(session)
        start = time.time()
        results = await hybrid.search("temporal craniotomy", limit=20)
        hybrid_time = (time.time() - start) * 1000
        assert hybrid_time < 600, f"Hybrid too slow: {hybrid_time}ms"
        print(f"Hybrid search: {hybrid_time:.2f}ms")


@pytest.mark.performance
@pytest.mark.asyncio
async def benchmark_parallel_execution():
    """
    Verify parallel execution speedup

    Target: At least 2x speedup for 4 parallel queries
    """

    orchestrator = ResearchOrchestrator()

    # Sequential execution
    queries = [
        "temporal craniotomy complications",
        "temporal lobe epilepsy surgery",
        "pterional approach technique",
        "skull base surgery"
    ]

    start = time.time()
    for query in queries:
        await orchestrator.pubmed_client.search(query, max_results=5)
    sequential_time = time.time() - start

    # Parallel execution
    start = time.time()
    await asyncio.gather(*[
        orchestrator.pubmed_client.search(query, max_results=5)
        for query in queries
    ])
    parallel_time = time.time() - start

    speedup = sequential_time / parallel_time
    assert speedup >= 2.0, f"Insufficient speedup: {speedup:.2f}x"
    print(f"Parallel speedup: {speedup:.2f}x")


@pytest.mark.performance
def benchmark_cache_performance():
    """
    Verify cache speedup

    Target: 100x+ speedup for cache hits
    """

    cache = CacheManager()

    # Cache miss (first query)
    start = time.time()
    result = cache.get('test_key', namespace='test')
    assert result is None

    # Set cache
    test_data = {'articles': [{'pmid': '12345678'} for _ in range(100)]}
    cache.set('test_key', test_data, namespace='test')

    # Cache hit
    start = time.time()
    result = cache.get('test_key', namespace='test')
    cache_hit_time = (time.time() - start) * 1000

    assert cache_hit_time < 10, f"Cache too slow: {cache_hit_time}ms"
    assert result == test_data
    print(f"Cache hit: {cache_hit_time:.2f}ms")
```

---

## Deployment Guide

### Production Deployment Checklist

#### 1. Environment Setup

```bash
# Install production dependencies
pip install -r requirements.txt

# Set up PostgreSQL with pgvector
sudo apt-get install postgresql-14 postgresql-14-pgvector

# Create database
sudo -u postgres createdb neurosurgical_kb
sudo -u postgres psql -d neurosurgical_kb -c "CREATE EXTENSION vector;"

# Set up Redis
sudo apt-get install redis-server
sudo systemctl enable redis-server
sudo systemctl start redis-server
```

#### 2. Configuration

**File:** `.env.production`

```bash
# Database
DATABASE_TYPE=postgresql
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=neurosurgical_kb
DATABASE_USER=app_user
DATABASE_PASSWORD=<strong_password>
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=<redis_password>

# AI Providers
ANTHROPIC_API_KEY=<your_key>
OPENAI_API_KEY=<your_key>
GOOGLE_AI_KEY=<your_key>

# PubMed
PUBMED_EMAIL=your_email@institution.edu
PUBMED_API_KEY=<optional_for_higher_rate_limit>

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json  # Structured logging for production

# Security
SECRET_KEY=<generate_with_secrets.token_hex(32)>
ALLOWED_HOSTS=your-domain.com,api.your-domain.com

# Performance
MAX_WORKERS=4  # For CPU-bound tasks
ASYNC_POOL_SIZE=100  # For I/O-bound tasks
```

#### 3. Database Migration

```bash
# Run Alembic migrations
alembic upgrade head

# Verify database structure
python3 << 'EOF'
from reference_library.database import get_db_manager
from sqlalchemy import inspect

db = get_db_manager()
inspector = inspect(db.engine)

print("Tables:", inspector.get_table_names())
print("PostgreSQL version:", db.engine.execute("SELECT version()").fetchone())
print("pgvector installed:", "vector" in inspector.get_table_names())
EOF
```

#### 4. Initial Data Load

```bash
# Index reference library
python3 scripts/index_library.py \
    --library-path /data/neurosurgical_books \
    --parallel-workers 4 \
    --extract-images

# Generate embeddings
python3 scripts/generate_embeddings.py \
    --batch-size 50 \
    --provider openai

# Build search indexes
python3 scripts/build_indexes.py
```

#### 5. Health Checks

**File:** `scripts/health_check.py`

```python
#!/usr/bin/env python3
"""
Production health check script
"""

import sys
import asyncio
from reference_library.database import get_db_manager
from search.hybrid_search import HybridSearchEngine
from research.cache_manager import CacheManager

async def check_health():
    checks = {
        'database': False,
        'search': False,
        'cache': False,
        'ai_providers': False
    }

    # Check database
    try:
        db = get_db_manager()
        result = db.engine.execute("SELECT 1").fetchone()
        checks['database'] = result[0] == 1
    except Exception as e:
        print(f"Database check failed: {e}")

    # Check search
    try:
        with get_db_session() as session:
            hybrid = HybridSearchEngine(session)
            stats = hybrid.get_stats()
            checks['search'] = stats['status'] == 'ready'
    except Exception as e:
        print(f"Search check failed: {e}")

    # Check cache
    try:
        cache = CacheManager()
        cache.set('health_check', 'ok', ttl=60)
        result = cache.get('health_check')
        checks['cache'] = result == 'ok'
    except Exception as e:
        print(f"Cache check failed: {e}")

    # Overall health
    all_healthy = all(checks.values())

    print(f"Health Check: {'PASS' if all_healthy else 'FAIL'}")
    for service, healthy in checks.items():
        status = 'âœ“' if healthy else 'âœ—'
        print(f"  {status} {service}")

    return 0 if all_healthy else 1

if __name__ == '__main__':
    sys.exit(asyncio.run(check_health()))
```

#### 6. Monitoring Setup

**Prometheus Metrics (optional):**

```python
# utils/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# Counters
search_requests_total = Counter(
    'search_requests_total',
    'Total search requests',
    ['search_type', 'status']
)

ai_requests_total = Counter(
    'ai_requests_total',
    'Total AI provider requests',
    ['provider', 'operation', 'status']
)

# Histograms
search_duration_seconds = Histogram(
    'search_duration_seconds',
    'Search request duration',
    ['search_type']
)

ai_request_duration_seconds = Histogram(
    'ai_request_duration_seconds',
    'AI request duration',
    ['provider', 'operation']
)

# Gauges
cache_hit_rate = Gauge(
    'cache_hit_rate',
    'Cache hit rate percentage'
)

indexed_chapters_total = Gauge(
    'indexed_chapters_total',
    'Total indexed chapters'
)
```

#### 7. Backup Strategy

```bash
# Daily PostgreSQL backup
pg_dump neurosurgical_kb | gzip > backup_$(date +%Y%m%d).sql.gz

# Weekly full backup including files
tar -czf full_backup_$(date +%Y%m%d).tar.gz \
    backup_*.sql.gz \
    /data/neurosurgical_books \
    /data/extracted_images \
    .env.production

# Upload to cloud storage
aws s3 cp full_backup_$(date +%Y%m%d).tar.gz \
    s3://your-backup-bucket/neurosurgical-kb/
```

---

## Troubleshooting Guide

### Common Issues

#### 1. Slow Search Performance

**Symptom:** Search queries taking > 1 second

**Diagnosis:**
```bash
# Check BM25 index
python3 << 'EOF'
from search.bm25_search import BM25SearchEngine
from reference_library.database import get_db_session

with get_db_session() as session:
    bm25 = BM25SearchEngine(session)
    stats = bm25.get_stats()
    print(f"Documents: {stats['total_documents']}")
    print(f"Terms: {stats['total_terms']}")

    # Rebuild if needed
    if stats['total_documents'] == 0:
        bm25._build_index()
EOF

# Check PostgreSQL indexes
psql neurosurgical_kb << 'EOF'
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0 AND schemaname = 'public';
EOF
```

**Solution:**
- Rebuild BM25 index
- Add missing database indexes
- Enable pgvector for semantic search

#### 2. AI Provider Timeouts

**Symptom:** Frequent "AI provider timeout" errors

**Diagnosis:**
```python
from ai.provider_router import ProviderRouter

router = ProviderRouter()
stats = router.get_circuit_breaker_stats()

for provider, status in stats.items():
    print(f"{provider}: {status}")
    # Check if circuit is open (too many failures)
```

**Solution:**
- Increase timeout settings
- Check API key validity
- Verify network connectivity
- Enable provider fallback

#### 3. Cache Misses

**Symptom:** Low cache hit rate (< 50%)

**Diagnosis:**
```python
from research.cache_manager import CacheManager

cache = CacheManager()
stats = cache.get_stats()

print(f"Hit rate: {stats['hit_rate']}%")
print(f"Total size: {stats['total_size_mb']}MB")
print(f"Entries: {stats['total_entries']}")
```

**Solution:**
- Increase cache TTL
- Verify Redis connection
- Check cache key generation (may be too specific)
- Monitor Redis memory usage

#### 4. Embedding Generation Failures

**Symptom:** Chapters without embeddings after generation

**Diagnosis:**
```python
from search.semantic_search import SemanticSearchEngine

with get_db_session() as session:
    semantic = SemanticSearchEngine(session)
    stats = semantic.get_stats()

    print(f"Coverage: {stats['coverage']}%")
    print(f"Chapters with embeddings: {stats['chapters_with_embeddings']}")
    print(f"Total chapters: {stats['total_chapters']}")
```

**Solution:**
- Check API keys
- Verify rate limiting
- Run batch embedding generation:
```bash
python3 scripts/generate_embeddings.py --retry-failed
```

---

## Performance Optimization Tips

### 1. Database Optimization

```sql
-- Add composite indexes for common queries
CREATE INDEX idx_chapter_search
ON chapters USING GIN (to_tsvector('english', title || ' ' || ai_summary));

-- Add vector index for similarity search (PostgreSQL + pgvector)
CREATE INDEX idx_chapter_embedding
ON chapters USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Analyze tables for query planner
ANALYZE chapters;
ANALYZE books;
ANALYZE images;
```

### 2. Caching Strategy

```python
# Cache expensive operations
CACHE_TTLS = {
    'pubmed_search': 7 * 24 * 3600,      # 7 days
    'chapter_embedding': 30 * 24 * 3600, # 30 days (rarely changes)
    'search_results': 1 * 3600,          # 1 hour
    'library_stats': 5 * 60,             # 5 minutes
}

# Implement cache warming for popular queries
async def warm_cache():
    popular_queries = [
        "temporal craniotomy",
        "brain tumor surgery",
        "skull base approach"
    ]

    for query in popular_queries:
        await hybrid.search(query, use_cache=True)
```

### 3. Parallel Processing

```python
# Use asyncio.gather for I/O-bound operations
results = await asyncio.gather(
    pubmed_client.search(query1),
    pubmed_client.search(query2),
    pubmed_client.search(query3),
    return_exceptions=True  # Don't fail all on one error
)

# Use multiprocessing for CPU-bound operations
from multiprocessing import Pool

with Pool(processes=4) as pool:
    embeddings = pool.map(generate_embedding, image_paths)
```

### 4. Connection Pooling

```python
# PostgreSQL connection pooling
engine = create_engine(
    DATABASE_URL,
    pool_size=20,              # Max persistent connections
    max_overflow=10,           # Max overflow connections
    pool_pre_ping=True,        # Verify connections
    pool_recycle=3600,         # Recycle after 1 hour
)

# Redis connection pooling
redis_pool = redis.ConnectionPool(
    host=REDIS_HOST,
    port=REDIS_PORT,
    max_connections=50,
    decode_responses=True
)
redis_client = redis.Redis(connection_pool=redis_pool)
```

---

## Quick Reference

### Common CLI Commands

```bash
# Library Management
python3 cli/library_commands.py add /path/to/book.pdf
python3 cli/library_commands.py list --with-chapters
python3 cli/library_commands.py search "temporal craniotomy"
python3 cli/library_commands.py stats
python3 cli/library_commands.py verify

# Search
python3 cli/search_commands.py hybrid "brain tumor surgery" --limit 10
python3 cli/search_commands.py semantic "surgical approach" --min-similarity 0.8
python3 cli/search_commands.py bm25 "craniotomy technique"

# Research
python3 cli/research_commands.py pubmed "temporal lobe epilepsy" --max-results 20
python3 cli/research_commands.py cache-stats

# Maintenance
python3 scripts/generate_embeddings.py --batch-size 50
python3 scripts/rebuild_search_index.py
python3 scripts/health_check.py
```

### Configuration Files

- `.env` - Development configuration
- `.env.production` - Production configuration
- `pytest.ini` - Testing configuration
- `pyproject.toml` - Dependencies and metadata

### Log Files

- `logs/application.log` - General application logs
- `logs/search.log` - Search query logs
- `logs/ai_provider.log` - AI provider requests/responses
- `logs/error.log` - Error logs only

---

## Conclusion

You now have a **complete, production-ready implementation guide** with:

âœ… **Phase 0:** Foundation utilities (exceptions, security, logging, config)
âœ… **Phase 1:** Reference library with PDF indexing and AI chapter detection
âœ… **Phase 2:** Hybrid search (BM25 + semantic + RRF)
âœ… **Phase 3:** Parallel research with PubMed and Redis caching
âœ… **Phase 4:** Image recommendations with diversity boosting
âœ… **Phase 5:** Section regeneration with version tracking
âœ… **Phase 6:** Multi-provider AI with circuit breaker
âœ… **Phase 7:** Update monitoring and interaction logging

**Total Implementation Time:** 7-8 weeks (56-64 hours)

**Key Achievements:**
- All Neurocore lessons integrated from day 1
- Comprehensive test coverage (unit + integration + performance)
- Production deployment guide
- Troubleshooting documentation
- Performance optimization strategies

**What You Can Build:**
- Intelligent medical textbook system
- Research-backed chapter generation
- Similar image recommendations
- Self-updating medical knowledge base

Start with Phase 0, follow each step carefully, and you'll have a robust, scalable system ready for production deployment.

**Good luck with your implementation! ðŸš€**
